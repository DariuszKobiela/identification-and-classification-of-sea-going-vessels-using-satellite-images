{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0742930-6116-4866-8572-dedbe9061135",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce0435d-11d9-46a9-8159-16212df85662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d835a98db96443bb5254898088e8153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics YOLOv8.0.5  Python-3.9.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, retina_masks=False, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, hydra={'output_subdir': None, 'run': {'dir': '.'}}, v5loader=True, save_dir=C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\n",
      "\n",
      "Dataset not found , missing paths ['C:\\\\Users\\\\user\\\\Documents\\\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\\\datasets\\\\coco128\\\\images\\\\train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3eac6e4335f446f8642b7585f0a2f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset download success  (2.2s), saved to \u001b[1mC:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\datasets\u001b[0m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\d\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\datasets\\coco128\\labels\\train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\dat\u001b[0m\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3      3.17G      1.211      1.406      1.248        189        640: 100%|██████████| 8/8 [00:06<00:00,  1.19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:23<0\n",
      "                   all        128        929      0.676       0.55       0.62      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3      4.07G      1.198      1.378      1.224        205        640: 100%|██████████| 8/8 [00:03<00:00,  2.54\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:22<0\n",
      "                   all        128        929      0.653      0.594      0.646      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3      4.07G      1.166      1.363      1.234        179        640: 100%|██████████| 8/8 [00:03<00:00,  2.55\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:24<0\n",
      "                   all        128        929       0.72      0.583      0.661      0.494\n",
      "\n",
      "3 epochs completed in 0.059 hours.\n",
      "Optimizer stripped from C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\\weights\\last.pt, 6.6MB\n",
      "Optimizer stripped from C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\\weights\\best.pt, 6.6MB\n",
      "\n",
      "Validating C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.5  Python-3.9.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Fusing layers... \n",
      "Model summary: 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:23<0\n",
      "                   all        128        929      0.723       0.58      0.661      0.495\n",
      "                person        128        254      0.806      0.671      0.774      0.551\n",
      "               bicycle        128          6          1       0.33      0.408      0.246\n",
      "                   car        128         46          1      0.217      0.322      0.198\n",
      "            motorcycle        128          5      0.688        0.8       0.92      0.751\n",
      "              airplane        128          6      0.689      0.833      0.886      0.651\n",
      "                   bus        128          7      0.839      0.714      0.723      0.645\n",
      "                 train        128          3      0.791          1      0.995       0.94\n",
      "                 truck        128         12          1      0.318      0.535      0.321\n",
      "                  boat        128          6      0.392      0.333      0.491      0.338\n",
      "         traffic light        128         14      0.684      0.143      0.202      0.139\n",
      "             stop sign        128          2          1      0.894      0.995      0.708\n",
      "                 bench        128          9          1      0.378      0.682      0.446\n",
      "                  bird        128         16       0.94      0.812      0.941      0.611\n",
      "                   cat        128          4      0.813          1      0.995      0.902\n",
      "                   dog        128          9      0.624      0.667       0.83      0.635\n",
      "                 horse        128          2      0.686          1      0.995      0.679\n",
      "              elephant        128         17      0.838      0.913      0.944      0.718\n",
      "                  bear        128          1      0.653          1      0.995      0.995\n",
      "                 zebra        128          4      0.866          1      0.995      0.964\n",
      "               giraffe        128          9      0.822          1      0.973      0.709\n",
      "              backpack        128          6      0.555      0.221       0.47      0.228\n",
      "              umbrella        128         18      0.762        0.5       0.71      0.458\n",
      "               handbag        128         19      0.541     0.0526      0.194      0.126\n",
      "                   tie        128          7      0.797      0.714      0.721      0.515\n",
      "              suitcase        128          4      0.713          1      0.945      0.616\n",
      "               frisbee        128          5      0.643        0.8      0.759      0.679\n",
      "                  skis        128          1      0.728          1      0.995      0.497\n",
      "             snowboard        128          7      0.824      0.675      0.702      0.496\n",
      "           sports ball        128          6          1      0.329      0.556       0.29\n",
      "                  kite        128         10      0.511        0.4      0.546      0.212\n",
      "          baseball bat        128          4      0.644      0.466      0.419      0.167\n",
      "        baseball glove        128          7      0.804      0.429      0.431      0.317\n",
      "            skateboard        128          5      0.683        0.4      0.559      0.354\n",
      "         tennis racket        128          7      0.746      0.571      0.598      0.366\n",
      "                bottle        128         18      0.691      0.374      0.461      0.276\n",
      "            wine glass        128         16      0.526      0.375      0.541      0.344\n",
      "                   cup        128         36      0.777      0.291      0.451      0.304\n",
      "                  fork        128          6      0.583      0.167      0.194      0.181\n",
      "                 knife        128         16      0.478        0.5      0.565      0.359\n",
      "                 spoon        128         22      0.664       0.18      0.338      0.204\n",
      "                  bowl        128         28      0.727       0.75      0.713      0.567\n",
      "                banana        128          1          0          0      0.142     0.0375\n",
      "              sandwich        128          2          1      0.818      0.995      0.945\n",
      "                orange        128          4          1       0.39      0.995      0.668\n",
      "              broccoli        128         11      0.417      0.273      0.272      0.222\n",
      "                carrot        128         24      0.663      0.792      0.771      0.503\n",
      "               hot dog        128          2      0.448          1      0.828      0.795\n",
      "                 pizza        128          5      0.874          1      0.995       0.85\n",
      "                 donut        128         14      0.645          1      0.911      0.821\n",
      "                  cake        128          4      0.668          1      0.995      0.883\n",
      "                 chair        128         35      0.557      0.486      0.506      0.268\n",
      "                 couch        128          6      0.784        0.5      0.656      0.487\n",
      "          potted plant        128         14      0.619      0.581      0.693      0.483\n",
      "                   bed        128          3          1      0.838      0.995      0.716\n",
      "          dining table        128         13      0.584      0.538      0.553      0.467\n",
      "                toilet        128          2      0.652        0.5      0.662       0.63\n",
      "                    tv        128          2      0.847          1      0.995      0.896\n",
      "                laptop        128          3          1      0.561      0.736      0.644\n",
      "                 mouse        128          2          1          0     0.0475     0.0142\n",
      "                remote        128          8       0.73        0.5      0.545      0.442\n",
      "            cell phone        128          8          1          0      0.249      0.147\n",
      "             microwave        128          3      0.366          1      0.863      0.755\n",
      "                  oven        128          5      0.531        0.4      0.386      0.299\n",
      "                  sink        128          6      0.372      0.167      0.259      0.171\n",
      "          refrigerator        128          5      0.715        0.4      0.514      0.392\n",
      "                  book        128         29      0.495      0.138      0.341      0.183\n",
      "                 clock        128          9      0.804      0.778      0.875      0.727\n",
      "                  vase        128          2      0.341          1      0.995      0.895\n",
      "              scissors        128          1          1          0     0.0711     0.0121\n",
      "            teddy bear        128         21      0.713      0.474      0.657      0.465\n",
      "            toothbrush        128          5          1      0.792      0.962      0.604\n",
      "Speed: 0.8ms pre-process, 3.8ms inference, 0.0ms loss, 4.8ms post-process per image\n",
      "Saving C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\\predictions.json...\n",
      "Results saved to \u001b[1mC:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\u001b[0m\n",
      "Ultralytics YOLOv8.0.5  Python-3.9.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Fusing layers... \n",
      "Model summary: 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\dat\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<0\n",
      "                   all        128        929      0.628      0.609      0.639      0.476\n",
      "                person        128        254      0.726      0.701      0.767      0.552\n",
      "               bicycle        128          6      0.654      0.333      0.387      0.317\n",
      "                   car        128         46      0.919      0.217      0.295       0.19\n",
      "            motorcycle        128          5      0.677      0.845      0.938      0.734\n",
      "              airplane        128          6      0.681      0.833      0.867      0.654\n",
      "                   bus        128          7      0.758      0.714      0.723      0.656\n",
      "                 train        128          3      0.679          1      0.995      0.907\n",
      "                 truck        128         12          1      0.461       0.53      0.339\n",
      "                  boat        128          6      0.383      0.333      0.519      0.379\n",
      "         traffic light        128         14      0.736      0.214      0.207       0.14\n",
      "             stop sign        128          2      0.761          1      0.995      0.648\n",
      "                 bench        128          9      0.839      0.582      0.641      0.358\n",
      "                  bird        128         16      0.826       0.89      0.954      0.629\n",
      "                   cat        128          4      0.744          1      0.995      0.877\n",
      "                   dog        128          9      0.546      0.778      0.801      0.623\n",
      "                 horse        128          2      0.577          1      0.995       0.46\n",
      "              elephant        128         17      0.725      0.941      0.932      0.718\n",
      "                  bear        128          1      0.625          1      0.995      0.995\n",
      "                 zebra        128          4      0.857          1      0.995      0.965\n",
      "               giraffe        128          9      0.755          1      0.963      0.719\n",
      "              backpack        128          6      0.519      0.365      0.444      0.235\n",
      "              umbrella        128         18      0.599      0.556      0.664       0.46\n",
      "               handbag        128         19      0.603      0.105        0.2      0.121\n",
      "                   tie        128          7      0.888      0.714      0.743      0.531\n",
      "              suitcase        128          4      0.465          1      0.788      0.524\n",
      "               frisbee        128          5      0.612        0.8      0.732      0.632\n",
      "                  skis        128          1      0.384          1      0.497      0.265\n",
      "             snowboard        128          7      0.806      0.714      0.725      0.466\n",
      "           sports ball        128          6       0.73      0.459      0.556      0.299\n",
      "                  kite        128         10      0.477      0.639      0.535      0.211\n",
      "          baseball bat        128          4      0.304       0.25        0.3      0.122\n",
      "        baseball glove        128          7      0.671      0.429       0.43      0.317\n",
      "            skateboard        128          5      0.827        0.6       0.61      0.446\n",
      "         tennis racket        128          7      0.564      0.377      0.493       0.32\n",
      "                bottle        128         18      0.391      0.389      0.404       0.24\n",
      "            wine glass        128         16      0.543        0.5      0.563      0.347\n",
      "                   cup        128         36      0.707      0.333      0.446      0.301\n",
      "                  fork        128          6      0.565      0.167      0.196      0.184\n",
      "                 knife        128         16      0.404      0.625      0.562      0.347\n",
      "                 spoon        128         22       0.43      0.227      0.363      0.199\n",
      "                  bowl        128         28      0.634       0.75      0.698      0.552\n",
      "                banana        128          1          0          0      0.142     0.0409\n",
      "              sandwich        128          2      0.398      0.695      0.497      0.497\n",
      "                orange        128          4          1      0.475      0.995      0.697\n",
      "              broccoli        128         11      0.421      0.266      0.275      0.221\n",
      "                carrot        128         24       0.54      0.792      0.748      0.513\n",
      "               hot dog        128          2      0.481          1      0.828      0.763\n",
      "                 pizza        128          5      0.671          1      0.995       0.81\n",
      "                 donut        128         14       0.61          1      0.898       0.79\n",
      "                  cake        128          4        0.7          1      0.995       0.89\n",
      "                 chair        128         35      0.509      0.543      0.504      0.282\n",
      "                 couch        128          6      0.606        0.5      0.675      0.535\n",
      "          potted plant        128         14      0.577      0.571      0.708      0.468\n",
      "                   bed        128          3          1      0.988      0.995      0.751\n",
      "          dining table        128         13       0.48      0.615      0.526      0.402\n",
      "                toilet        128          2      0.627        0.5      0.828      0.796\n",
      "                    tv        128          2      0.628          1      0.828      0.713\n",
      "                laptop        128          3          1      0.616       0.72      0.605\n",
      "                 mouse        128          2          1          0     0.0452    0.00903\n",
      "                remote        128          8      0.698        0.5      0.573       0.48\n",
      "            cell phone        128          8          0          0      0.119     0.0625\n",
      "             microwave        128          3      0.502          1      0.913      0.748\n",
      "                  oven        128          5      0.499        0.4      0.413      0.329\n",
      "                  sink        128          6      0.369      0.167      0.235      0.146\n",
      "          refrigerator        128          5      0.508      0.415      0.625      0.482\n",
      "                  book        128         29      0.525      0.172      0.401      0.209\n",
      "                 clock        128          9      0.795      0.889      0.897      0.743\n",
      "                  vase        128          2      0.305          1      0.828      0.745\n",
      "              scissors        128          1          1          0     0.0765     0.0267\n",
      "            teddy bear        128         21      0.544      0.476      0.624      0.405\n",
      "            toothbrush        128          5          1      0.792      0.995      0.638\n",
      "Speed: 0.4ms pre-process, 3.9ms inference, 0.0ms loss, 4.7ms post-process per image\n",
      "Downloading https://ultralytics.com/images/bus.jpg to bus.jpg...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3298ac0811484798a22e57d940511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/476k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.5  Python-3.9.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Fusing layers... \n",
      "Model summary: 168 layers, 3151904 parameters, 0 gradients\n",
      "image 1/1 C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\notebooks\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 31.1ms\n",
      "Speed: 1.0ms pre-process, 31.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Ultralytics YOLOv8.0.5  Python-3.9.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Fusing layers... \n",
      "Model summary: 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from C:\\Users\\user\\Documents\\identification-and-classification-of-sea-going-vessels-using-satellite-images\\runs\\detect\\train\\weights\\best.pt with output shape (1, 84, 8400) (6.3 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirement \"onnx>=1.12.0\" not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.13.0-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     --------------------------------------- 12.2/12.2 MB 34.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (1.23.5)\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.13.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure  8.0s: Unsupported ONNX opset version: 17\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "success = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb68285-94eb-4ac4-9961-b8e0ac3043cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee66ee1-9c23-47d2-b9f1-8c5e724434ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
